{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "ea0bebe9-a63d-4c46-8163-509c1e67f544",
      "cell_type": "markdown",
      "source": "## **Target Trial Emulation**  \n### *By Jyreneah Angel and Nicole Grace Joligon* ",
      "metadata": {}
    },
    {
      "id": "e61e5306-104b-474b-9b6d-f599ac4b91fc",
      "cell_type": "markdown",
      "source": "## **IMPORT LIBRARIES**",
      "metadata": {}
    },
    {
      "id": "8557d594-73a4-488d-8ed3-cfd069ed9f71",
      "cell_type": "code",
      "source": "import os\nfrom tempfile import mkdtemp\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ndata_censored = pd.read_csv(\"data_censored.csv\")\nprint(data_censored.head())",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "   id  age  treatment  x1        x2  event_time  censoring  censored\n0   1   30          1   0 -0.049161    7.809887          0         1\n1   2   64          1   0  1.593443    7.522101          0         1\n2   3   59          1   1  0.765598   10.867286          0         1\n3   4   32          0   0 -0.071377   13.681152          0         1\n4   5   75          0   1 -1.716098   22.671353          0         1\n"
        }
      ],
      "execution_count": 3
    },
    {
      "id": "005ccc80-adea-4058-b1ed-50fd7ecb2970",
      "cell_type": "markdown",
      "source": "## **Define Estimands**",
      "metadata": {}
    },
    {
      "id": "5f44062a-a1aa-4d13-999b-95e2cd534513",
      "cell_type": "code",
      "source": "trial_pp = {\"estimand\": \"PP\"}\ntrial_itt = {\"estimand\": \"ITT\"}\n\ntrial_pp.update({\n    \"data\": data_censored.copy(),  \n    \"id_col\": \"id\",\n    \"period_col\": \"period\",\n    \"treatment_col\": \"treatment\",\n    \"outcome_col\": \"outcome\",\n    \"eligible_col\": \"eligible\"\n})\n\ntrial_itt = trial_pp.copy()\ntrial_itt[\"estimand\"] = \"ITT\" \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "id": "48c14b53-079d-4098-82e1-b4443fb01331",
      "cell_type": "markdown",
      "source": "## **Create Directories**",
      "metadata": {}
    },
    {
      "id": "51b2ec47-7536-448b-aa3c-bbfcd6c64448",
      "cell_type": "code",
      "source": "from tempfile import TemporaryDirectory  \n\npp_temp_dir = os.path.join(mkdtemp(), \"per_protocol\")  \nos.makedirs(pp_temp_dir, exist_ok=True)  \n\nitt_temp_dir = os.path.join(mkdtemp(), \"intention_to_treat\")  \nos.makedirs(itt_temp_dir, exist_ok=True)  \n\nprint(f\"Per-Protocol Directory: {pp_temp_dir}\")  \nprint(f\"Intention-To-Treat Directory: {itt_temp_dir}\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Per-Protocol Directory: /tmp/tmpjrcw3vnx/per_protocol\nIntention-To-Treat Directory: /tmp/tmpfeqnu_df/intention_to_treat\n"
        }
      ],
      "execution_count": 7
    },
    {
      "id": "51c3c433-ada4-4089-afe0-fe287bd2e458",
      "cell_type": "markdown",
      "source": "## **Define Functions**",
      "metadata": {}
    },
    {
      "id": "f2864335-10ed-4460-b2fb-3bc2a02e6ac3",
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\n\ndef compute_treatment_weights(df, num_formula, denom_formula, treat_col):\n    \"\"\"Compute inverse probability weights for treatment assignment.\"\"\"\n    \n    num_model = LogisticRegression()\n    num_model.fit(df[num_formula.split(\" + \")], df[treat_col])\n\n    denom_model = LogisticRegression()\n    denom_model.fit(df[denom_formula.split(\" + \")], df[treat_col])\n\n    num_probs = num_model.predict_proba(df[num_formula.split(\" + \")])[:, 1]\n    denom_probs = denom_model.predict_proba(df[denom_formula.split(\" + \")])[:, 1]\n\n    return num_probs / denom_probs\n\ndef compute_censoring_weights(df, censor_col, num_formula, denom_formula):\n    \"\"\"Compute inverse probability weights for informative censoring.\"\"\"\n   \n    num_model = LogisticRegression()\n    num_model.fit(df[num_formula.split(\" + \")], 1 - df[censor_col])\n\n    denom_model = LogisticRegression()\n    denom_model.fit(df[denom_formula.split(\" + \")], 1 - df[censor_col])\n\n    num_probs = num_model.predict_proba(df[num_formula.split(\" + \")])[:, 1]\n    denom_probs = denom_model.predict_proba(df[denom_formula.split(\" + \")])[:, 1]\n\n    return num_probs / denom_probs\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "id": "ccae9b7e-1458-4aff-9fdd-376031ecf458",
      "cell_type": "markdown",
      "source": "## **Expand the Dataset**",
      "metadata": {}
    },
    {
      "id": "1eff04bc-ba1d-461f-8967-beaba6bbb971",
      "cell_type": "code",
      "source": "def create_trial_dataset(df, id_col, period_col, treat_col, outcome_col):\n    \"\"\"Generate an expanded dataset for sequential trials.\"\"\"\n    \n    # Debugging: Print available columns\n    print(\"Available columns:\", df.columns.tolist())\n\n    if period_col not in df.columns:\n        raise KeyError(f\"Column '{period_col}' not found in the dataset. Available columns: {df.columns.tolist()}\")\n\n    trials = []\n    \n    # Loop through each unique period and expand the dataset\n    for current_period in sorted(df[period_col].unique()):\n        temp_df = df[df[period_col] <= current_period].copy()\n        temp_df[\"trial_stage\"] = current_period  # Rename for differentiation\n        trials.append(temp_df)\n\n    return pd.concat(trials).reset_index(drop=True)\n\n# Check dataset before expansion\nprint(\"First few rows of trial_pp['data']:\")\nprint(trial_pp[\"data\"].head())\n\npp_trial_expanded = create_trial_dataset(\n    df=trial_pp[\"data\"],\n    id_col=\"id\",\n    period_col=\"event_time\",  # Change this to the correct column\n    treat_col=\"treatment\",\n    outcome_col=\"censored\"\n)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "First few rows of trial_pp['data']:\n   id  age  treatment  x1        x2  event_time  censoring  censored\n0   1   30          1   0 -0.049161    7.809887          0         1\n1   2   64          1   0  1.593443    7.522101          0         1\n2   3   59          1   1  0.765598   10.867286          0         1\n3   4   32          0   0 -0.071377   13.681152          0         1\n4   5   75          0   1 -1.716098   22.671353          0         1\nAvailable columns: ['id', 'age', 'treatment', 'x1', 'x2', 'event_time', 'censoring', 'censored']\n"
        }
      ],
      "execution_count": 25
    },
    {
      "id": "b30177f3-2cbe-410c-b51f-73ce43b15a6b",
      "cell_type": "markdown",
      "source": "## **Calculate Weights**",
      "metadata": {}
    },
    {
      "id": "3b2053c7-3039-4cb2-96e1-8eae779e4f69",
      "cell_type": "code",
      "source": "# Ensure trial_pp_expanded has the expected columns\nprint(\"Columns in trial_pp_expanded:\", pp_trial_.columns)\n\n# Compute switch weights\ntrial_pp[\"switch_weights\"] = calculate_weights(\n    data=trial_pp_expanded,\n    numerator_formula=\"age\",\n    denominator_formula=\"age + x1 + x3\",\n    treatment_col=\"treatment\"\n)\n\n# Compute censor weights\ntrial_pp[\"censor_weights\"] = calculate_censor_weights(\n    data=trial_pp_expanded,\n    censor_event=\"censored\",\n    numerator_formula=\"x2\",\n    denominator_formula=\"x2 + x1\"\n)\n\ntrial_itt[\"censor_weights\"] = calculate_censor_weights(\n    data=trial_pp_expanded,\n    censor_event=\"censored\",\n    numerator_formula=\"x2\",\n    denominator_formula=\"x2 + x1\"\n)\n\n# Handle potential NaN or Inf values in weights\ntrial_pp[\"switch_weights\"] = np.nan_to_num(trial_pp[\"switch_weights\"], nan=1.0, posinf=10, neginf=0.1)\ntrial_pp[\"censor_weights\"] = np.nan_to_num(trial_pp[\"censor_weights\"], nan=1.0, posinf=10, neginf=0.1)\ntrial_itt[\"censor_weights\"] = np.nan_to_num(trial_itt[\"censor_weights\"], nan=1.0, posinf=10, neginf=0.1)\n\n# Combine weights safely\ntrial_pp[\"weights\"] = trial_pp[\"switch_weights\"] * trial_pp[\"censor_weights\"]\ntrial_itt[\"weights\"] = trial_itt[\"censor_weights\"]\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'pp_trial_' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure trial_pp_expanded has the expected columns\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns in trial_pp_expanded:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mpp_trial_\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Compute switch weights\u001b[39;00m\n\u001b[1;32m      5\u001b[0m trial_pp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswitch_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m calculate_weights(\n\u001b[1;32m      6\u001b[0m     data\u001b[38;5;241m=\u001b[39mtrial_pp_expanded,\n\u001b[1;32m      7\u001b[0m     numerator_formula\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     denominator_formula\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage + x1 + x3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     treatment_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtreatment\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pp_trial_' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 33
    },
    {
      "id": "19f74ced-2b37-4b04-b5f5-5e18c03e7009",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}