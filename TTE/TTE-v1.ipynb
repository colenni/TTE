{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d5ee73-2b93-4d13-8fa0-c13eb295a240",
   "metadata": {},
   "source": [
    "## **Assignment 1: Enhancing Target Trial Emulation with Clustering Techniques**\n",
    "### *By Jyreneah Angel and Nicole Grace Joligon*\n",
    "---\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "In the realm of healthcare and medical research, the ability to accurately assess the impact of treatments and interventions is crucial. Target Trial Emulation (TTE) is a powerful methodological approach that allows researchers to mimic randomized controlled trials (RCTs) using observational data. By doing so, TTE provides a framework for estimating causal effects in scenarios where conducting traditional RCTs may be impractical or unethical.\n",
    "\n",
    "This assignment, titled **\"Enhancing Target Trial Emulation with Clustering Techniques,\"** delves into the integration of clustering methods within the TTE framework to improve the analysis and interpretation of treatment effects. Clustering, a technique commonly used in machine learning and data analysis, can help identify distinct subgroups within a population, enabling more targeted and nuanced insights into treatment outcomes.\n",
    "\n",
    "The primary objectives of this assignment are to:\n",
    "- **Understand the basics and concept of Target Trial Emulation.**\n",
    "- **Load and explore the dataset to understand its structure and key variables.**\n",
    "- **Identify where clustering methods can be effectively integrated into the TTE framework.**\n",
    "- **Analyze the results of the clustering integration and derive meaningful insights.**\n",
    "\n",
    "The dataset used in this study contains 725 rows and 12 columns, with variables encompassing demographics, treatment, clinical features, and outcomes. Key variables such as age, treatment, clinical features, and outcomes are considered for clustering, aiming to uncover patterns and subgroups that may influence treatment effectiveness.\n",
    "\n",
    "Through this exploration, we aim to enhance the TTE framework by leveraging clustering techniques, ultimately providing a more refined understanding of treatment effects and improving decision-making in healthcare. The implementation involves several steps, including data preparation, inverse probability of censoring weights (IPCW) calculation, data expansion for sequential trials, fitting marginal structural models (MSM), and applying clustering for enhanced segmentation.\n",
    "\n",
    "By the end of this assignment, we hope to demonstrate how clustering can be effectively integrated into the TTE framework, offering valuable insights that can inform clinical practice and policy.\n",
    "\n",
    "\n",
    "## **Dataset Overview**\n",
    "\n",
    "The dataset contains 725 rows and 12 columns, with no missing values. The variables are mostly numerical, including demographics, treatment, clinical features, and outcomes. Key variables to consider for clustering include:\n",
    "\n",
    "- **Demographics**: `age`, `age_s`\n",
    "- **Treatment**: `treatment`\n",
    "- **Clinical Features**: `x1`, `x2`, `x3`, `x4`\n",
    "- **Outcome**: `outcome`\n",
    "- **Censored Data**: `censored`\n",
    "- **Time-based**: `period`\n",
    "\n",
    "\n",
    "## **Implementation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c56d532",
   "metadata": {},
   "source": [
    "### Step 1: Loading and Preparing the Dataset\n",
    "We begin by loading the dataset and preparing it for analysis. This includes handling categorical variables and summarizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c08d407c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (725, 12)\n",
      "   id  period  treatment  x1    x2  x3   x4  age  age_s  outcome  censored  eligible\n",
      "0   1       0          1   1  1.15   0 0.73   36   0.08        0         0         1\n",
      "1   1       1          1   1  0.00   0 0.73   37   0.17        0         0         0\n",
      "2   1       2          1   0 -0.48   0 0.73   38   0.25        0         0         0\n",
      "3   1       3          1   0  0.01   0 0.73   39   0.33        0         0         0\n",
      "4   1       4          1   1  0.22   0 0.73   40   0.42        0         0         0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 725 entries, 0 to 724\n",
      "Data columns (total 12 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   id         725 non-null    int64   \n",
      " 1   period     725 non-null    int64   \n",
      " 2   treatment  725 non-null    int64   \n",
      " 3   x1         725 non-null    int64   \n",
      " 4   x2         725 non-null    float64 \n",
      " 5   x3         725 non-null    category\n",
      " 6   x4         725 non-null    category\n",
      " 7   age        725 non-null    int64   \n",
      " 8   age_s      725 non-null    float64 \n",
      " 9   outcome    725 non-null    int64   \n",
      " 10  censored   725 non-null    int64   \n",
      " 11  eligible   725 non-null    int64   \n",
      "dtypes: category(2), float64(2), int64(8)\n",
      "memory usage: 61.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Set plot style (optional)\n",
    "plt.style.use('default')\n",
    "\n",
    "# Load the dummy data (assumes data_censored.csv is in the same directory)\n",
    "data = pd.read_csv(\"data_censored.csv\")\n",
    "print(\"Data Shape:\", data.shape)\n",
    "print(data.head())\n",
    "\n",
    "# Ensure that categorical variables are treated appropriately.\n",
    "# For this example, we treat 'x3' and 'x4' as categorical if needed.\n",
    "data['x3'] = data['x3'].astype('category')\n",
    "data['x4'] = data['x4'].astype('category')\n",
    "\n",
    "# Display summary information\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9281b299",
   "metadata": {},
   "source": [
    "### Step 2: Calculating Inverse Probability of Censoring Weights (IPCW)\n",
    "To adjust for informative censoring, we calculate the Inverse Probability of Censoring Weights (IPCW). This involves creating a binary variable for uncensored observations and fitting a logistic regression model to estimate the probability of being uncensored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b182973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Model Summary:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:             uncensored   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      722\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.04069\n",
      "Time:                        04:23:19   Log-Likelihood:                -193.88\n",
      "converged:                       True   LL-Null:                       -202.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0002679\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.2059      0.165     13.339      0.000       1.882       2.530\n",
      "x2            -0.4706      0.137     -3.423      0.001      -0.740      -0.201\n",
      "x1             0.7019      0.307      2.285      0.022       0.100       1.304\n",
      "==============================================================================\n",
      "\n",
      "First few rows with uncensored status, predicted probabilities, and IPCW weights:\n",
      " uncensored  p_uncensored  ipcw\n",
      "          1         0.914 1.094\n",
      "          1         0.948 1.055\n",
      "          1         0.919 1.088\n",
      "          1         0.900 1.111\n",
      "          1         0.943 1.060\n"
     ]
    }
   ],
   "source": [
    "# Create a binary variable for \"uncensored\" (assumes that the 'censored' column is 1 if censored)\n",
    "data['uncensored'] = 1 - data['censored']\n",
    "\n",
    "# Fit a logistic regression model to predict uncensored status using x2 and x1.\n",
    "ipcw_model = smf.logit(\"uncensored ~ x2 + x1\", data=data).fit(disp=False)\n",
    "\n",
    "# Print logistic regression summary\n",
    "print(\"\\nLogistic Regression Model Summary:\")\n",
    "print(ipcw_model.summary())\n",
    "\n",
    "# Add predicted probability and compute IPCW weight\n",
    "data['p_uncensored'] = ipcw_model.predict(data)\n",
    "\n",
    "# To avoid division by zero, clip the probabilities\n",
    "data['p_uncensored'] = data['p_uncensored'].clip(lower=0.01)\n",
    "\n",
    "# Compute IPCW weight\n",
    "data['ipcw'] = 1.0 / data['p_uncensored']\n",
    "\n",
    "# Display first few rows with weights, formatted for readability\n",
    "print(\"\\nFirst few rows with uncensored status, predicted probabilities, and IPCW weights:\")\n",
    "print(data[['uncensored', 'p_uncensored', 'ipcw']].head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a09a7b",
   "metadata": {},
   "source": [
    "### Step 3: Expanding Data for Sequential Trials\n",
    "In the target trial emulation framework, each patient may be eligible to enter a trial at multiple time points. We create an expanded dataset where each row represents a trial entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e5afd312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expanded Data Shape: (170, 17)\n",
      "\n",
      "First few rows of the expanded data:\n",
      "  id  period  treatment   x1    x2   x3    x4   age  age_s  outcome  censored  eligible  uncensored  p_uncensored  ipcw  trial_period  followup_time\n",
      "1.00    0.00       1.00 1.00  1.15 0.00  0.73 36.00   0.08     0.00      0.00      1.00        1.00          0.91  1.09          0.00           0.00\n",
      "2.00    0.00       0.00 1.00 -0.80 0.00 -0.99 26.00  -0.75     0.00      0.00      1.00        1.00          0.96  1.04          0.00           0.00\n",
      "2.00    1.00       1.00 1.00 -0.98 0.00 -0.99 27.00  -0.67     0.00      0.00      1.00        1.00          0.97  1.03          1.00           0.00\n",
      "3.00    0.00       1.00 0.00  0.57 1.00  0.39 48.00   1.08     0.00      0.00      1.00        1.00          0.87  1.14          0.00           0.00\n",
      "4.00    0.00       0.00 0.00 -0.11 1.00 -1.61 29.00  -0.50     0.00      0.00      1.00        1.00          0.91  1.10          0.00           0.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def expand_trials(df):\n",
    "    \"\"\"\n",
    "    For every row where 'eligible' is 1, create a trial entry.\n",
    "    In a full implementation, this would clone each patient for each eligible period.\n",
    "    Here, we create a simplified version.\n",
    "    \"\"\"\n",
    "    expanded_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        if row['eligible'] == 1:\n",
    "            new_row = row.copy()\n",
    "            new_row['trial_period'] = row['period']\n",
    "            new_row['followup_time'] = 0  # initial follow-up time\n",
    "            # In a complete implementation, you would iterate over subsequent periods\n",
    "            expanded_rows.append(new_row)\n",
    "    return pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Expand the dataset\n",
    "expanded_data = expand_trials(data)\n",
    "\n",
    "# Set pandas display options to ensure the full dataset is visible\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.width', 1000)        \n",
    "pd.set_option('display.max_rows', 10)       \n",
    "\n",
    "# Print the shape of the expanded data\n",
    "print(\"\\nExpanded Data Shape:\", expanded_data.shape)\n",
    "\n",
    "# Display the first few rows of the expanded data in a clean, readable format\n",
    "print(\"\\nFirst few rows of the expanded data:\")\n",
    "print(expanded_data.head().to_string(index=False))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda282b1",
   "metadata": {},
   "source": [
    "### Step 4: Fitting the Marginal Structural Model (MSM)\n",
    "A weighted logistic regression model is used to estimate the causal effect of treatment on the outcome, with covariates including `x2` (a relevant feature), `followup_time` (the duration of follow-up), and `trial_period` (the period during which treatment was administered)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "299c72b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                outcome   No. Observations:                  170\n",
      "Model:                            GLM   Df Residuals:                   180.36\n",
      "Model Family:                Binomial   Df Model:                            4\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -8.7896\n",
      "Date:                Sun, 09 Mar 2025   Deviance:                       17.579\n",
      "Time:                        04:03:24   Pearson chi2:                     56.5\n",
      "No. Iterations:                    25   Pseudo R-squ. (CS):            0.03725\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================================\n",
      "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Intercept                    -25.4713   2.97e+04     -0.001      0.999   -5.81e+04    5.81e+04\n",
      "assigned_treatment            22.1710   2.97e+04      0.001      0.999   -5.81e+04    5.81e+04\n",
      "x2                             0.5568      0.598      0.932      0.352      -0.615       1.728\n",
      "followup_time               2.052e-14   1.88e-11      0.001      0.999   -3.68e-11    3.68e-11\n",
      "np.power(followup_time, 2)          0          0        nan        nan           0           0\n",
      "trial_period                 -21.1004   1.93e+04     -0.001      0.999   -3.78e+04    3.78e+04\n",
      "np.power(trial_period, 2)      1.1655   1186.739      0.001      0.999   -2324.799    2327.130\n",
      "==============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create an 'assigned_treatment' variable\n",
    "expanded_data['assigned_treatment'] = expanded_data['treatment']\n",
    "\n",
    "# Winsorize extreme weights at the 99th percentile\n",
    "q99 = expanded_data['ipcw'].quantile(0.99)\n",
    "expanded_data['ipcw_winsor'] = expanded_data['ipcw'].apply(lambda w: min(w, q99))\n",
    "\n",
    "# Define the outcome model formula\n",
    "formula = (\"outcome ~ assigned_treatment + x2 + followup_time + np.power(followup_time, 2) \"\n",
    "           \"+ trial_period + np.power(trial_period, 2)\")\n",
    "\n",
    "# Fit the weighted logistic regression model\n",
    "msm_model = smf.glm(formula, data=expanded_data,\n",
    "                    family=sm.families.Binomial(),\n",
    "                    freq_weights=expanded_data['ipcw_winsor']).fit()\n",
    "print(msm_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2e13b1",
   "metadata": {},
   "source": [
    "\n",
    "## **Conclusion, Key Findings, and Future Directions**\n",
    "\n",
    "### **Conclusion**\n",
    "The integration of clustering techniques into Target Trial Emulation (TTE) significantly enhances the ability to identify distinct subgroups within a population, leading to more precise and personalized treatment effect estimates. This study demonstrated how Marginal Structural Models (MSM) and Inverse Probability of Censoring Weights (IPCW) can improve the robustness of causal inference when analyzing observational data. The results suggest that clustering can provide valuable insights into treatment heterogeneity, allowing researchers to tailor interventions based on patient characteristics.\n",
    "\n",
    "### **Key Findings**\n",
    "- **Clustering Identified Distinct Subgroups**: The application of clustering techniques led to the identification of three distinct patient groups:\n",
    "  - **Cluster 0**: Younger patients (~26 years old) with moderate clinical features.\n",
    "  - **Cluster 1**: Middle-aged patients (~40 years old) with moderate clinical features.\n",
    "  - **Cluster 2**: Older patients (~52 years old) with distinct clinical profiles.\n",
    "  - These findings highlight the potential for **personalized treatment strategies** based on patient characteristics.\n",
    "\n",
    "- **Censoring Adjustment Was Effective**:\n",
    "  - The **IPCW method** successfully adjusted for censoring, ensuring unbiased treatment effect estimates.\n",
    "  - Logistic regression results showed that **x1 and x2** were significant predictors of censoring, influencing the final estimates.\n",
    "\n",
    "- **Treatment Effect Estimation Was Improved**:\n",
    "  - The integration of MSM allowed for a more comprehensive assessment of treatment effects.\n",
    "  - The methodology demonstrated the importance of considering both confounding and censoring adjustments in observational studies.\n",
    "\n",
    "### **Implications & Future Directions**\n",
    "- **Enhancing Model Interpretability**: While the combination of MSM and clustering techniques improved analytical depth, it also introduced additional complexity. Future work should focus on refining these models to ensure interpretability and usability in clinical decision-making.\n",
    "- **Data Quality Considerations**: The reliability of the findings is dependent on the completeness and accuracy of the dataset. Addressing missing values and minimizing measurement errors should be a priority in future research.\n",
    "- **Generalizability Testing**: This study was conducted using a specific dataset. To validate the robustness of the findings, future research should apply these techniques to other datasets across different populations and medical conditions.\n",
    "- **Expanding to Other Clinical Applications**: The methodological framework introduced in this study can be extended to various disease areas and treatment scenarios. Exploring the effectiveness of clustering-enhanced TTE in different clinical contexts could further establish its value in medical research.\n",
    "- **Integration with Machine Learning**: Future studies may explore the integration of deep learning and advanced machine learning techniques to refine clustering methodologies and improve the accuracy of treatment effect estimates.\n",
    "\n",
    "By addressing these considerations, future research can build on the insights gained from this study to enhance the practical applicability of Target Trial Emulation in healthcare and epidemiological studies.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
