{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d5ee73-2b93-4d13-8fa0-c13eb295a240",
   "metadata": {},
   "source": [
    "## **Assignment 1: Enhancing Target Trial Emulation with Clustering Techniques**\n",
    "### *By Jyreneah Angel and Nicole Grace Joligon*\n",
    "---\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "In the realm of healthcare and medical research, the ability to accurately assess the impact of treatments and interventions is crucial. Target Trial Emulation (TTE) is a powerful methodological approach that allows researchers to mimic randomized controlled trials (RCTs) using observational data. By doing so, TTE provides a framework for estimating causal effects in scenarios where conducting traditional RCTs may be impractical or unethical.\n",
    "\n",
    "This assignment, titled **\"Enhancing Target Trial Emulation with Clustering Techniques,\"** delves into the integration of clustering methods within the TTE framework to improve the analysis and interpretation of treatment effects. Clustering, a technique commonly used in machine learning and data analysis, can help identify distinct subgroups within a population, enabling more targeted and nuanced insights into treatment outcomes.\n",
    "\n",
    "The primary objectives of this assignment are to:\n",
    "- **Understand the basics and concept of Target Trial Emulation.**\n",
    "- **Load and explore the dataset to understand its structure and key variables.**\n",
    "- **Identify where clustering methods can be effectively integrated into the TTE framework.**\n",
    "- **Analyze the results of the clustering integration and derive meaningful insights.**\n",
    "\n",
    "The dataset used in this study contains 725 rows and 12 columns, with variables encompassing demographics, treatment, clinical features, and outcomes. Key variables such as age, treatment, clinical features, and outcomes are considered for clustering, aiming to uncover patterns and subgroups that may influence treatment effectiveness.\n",
    "\n",
    "Through this exploration, we aim to enhance the TTE framework by leveraging clustering techniques, ultimately providing a more refined understanding of treatment effects and improving decision-making in healthcare. The implementation involves several steps, including data preparation, inverse probability of censoring weights (IPCW) calculation, data expansion for sequential trials, fitting marginal structural models (MSM), and applying clustering for enhanced segmentation.\n",
    "\n",
    "By the end of this assignment, we hope to demonstrate how clustering can be effectively integrated into the TTE framework, offering valuable insights that can inform clinical practice and policy.\n",
    "\n",
    "\n",
    "## **Dataset Overview**\n",
    "\n",
    "The dataset contains 725 rows and 12 columns, with no missing values. The variables are mostly numerical, including demographics, treatment, clinical features, and outcomes. Key variables to consider for clustering include:\n",
    "\n",
    "- **Demographics**: `age`, `age_s`\n",
    "- **Treatment**: `treatment`\n",
    "- **Clinical Features**: `x1`, `x2`, `x3`, `x4`\n",
    "- **Outcome**: `outcome`\n",
    "- **Censored Data**: `censored`\n",
    "- **Time-based**: `period`\n",
    "\n",
    "\n",
    "## **Implementation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c56d532",
   "metadata": {},
   "source": [
    "### Step 1: Loading and Preparing the Dataset\n",
    "We begin by loading the dataset and preparing it for analysis. This includes handling categorical variables and summarizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c08d407c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (725, 12)\n",
      "   id  period  treatment  x1    x2  x3   x4  age  age_s  outcome  censored  eligible\n",
      "0   1       0          1   1  1.15   0 0.73   36   0.08        0         0         1\n",
      "1   1       1          1   1  0.00   0 0.73   37   0.17        0         0         0\n",
      "2   1       2          1   0 -0.48   0 0.73   38   0.25        0         0         0\n",
      "3   1       3          1   0  0.01   0 0.73   39   0.33        0         0         0\n",
      "4   1       4          1   1  0.22   0 0.73   40   0.42        0         0         0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 725 entries, 0 to 724\n",
      "Data columns (total 12 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   id         725 non-null    int64   \n",
      " 1   period     725 non-null    int64   \n",
      " 2   treatment  725 non-null    int64   \n",
      " 3   x1         725 non-null    int64   \n",
      " 4   x2         725 non-null    float64 \n",
      " 5   x3         725 non-null    category\n",
      " 6   x4         725 non-null    category\n",
      " 7   age        725 non-null    int64   \n",
      " 8   age_s      725 non-null    float64 \n",
      " 9   outcome    725 non-null    int64   \n",
      " 10  censored   725 non-null    int64   \n",
      " 11  eligible   725 non-null    int64   \n",
      "dtypes: category(2), float64(2), int64(8)\n",
      "memory usage: 61.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Set plot style (optional)\n",
    "plt.style.use('default')\n",
    "\n",
    "# Load the dummy data (assumes data_censored.csv is in the same directory)\n",
    "data = pd.read_csv(\"data_censored.csv\")\n",
    "print(\"Data Shape:\", data.shape)\n",
    "print(data.head())\n",
    "\n",
    "# Ensure that categorical variables are treated appropriately.\n",
    "# For this example, we treat 'x3' and 'x4' as categorical if needed.\n",
    "data['x3'] = data['x3'].astype('category')\n",
    "data['x4'] = data['x4'].astype('category')\n",
    "\n",
    "# Display summary information\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9281b299",
   "metadata": {},
   "source": [
    "### Step 2: Calculating Inverse Probability of Censoring Weights (IPCW)\n",
    "To adjust for informative censoring, we calculate the Inverse Probability of Censoring Weights (IPCW). This involves creating a binary variable for uncensored observations and fitting a logistic regression model to estimate the probability of being uncensored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b182973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Model Summary:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:             uncensored   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      722\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.04069\n",
      "Time:                        04:23:19   Log-Likelihood:                -193.88\n",
      "converged:                       True   LL-Null:                       -202.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0002679\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.2059      0.165     13.339      0.000       1.882       2.530\n",
      "x2            -0.4706      0.137     -3.423      0.001      -0.740      -0.201\n",
      "x1             0.7019      0.307      2.285      0.022       0.100       1.304\n",
      "==============================================================================\n",
      "\n",
      "First few rows with uncensored status, predicted probabilities, and IPCW weights:\n",
      " uncensored  p_uncensored  ipcw\n",
      "          1         0.914 1.094\n",
      "          1         0.948 1.055\n",
      "          1         0.919 1.088\n",
      "          1         0.900 1.111\n",
      "          1         0.943 1.060\n"
     ]
    }
   ],
   "source": [
    "# Create a binary variable for \"uncensored\" (assumes that the 'censored' column is 1 if censored)\n",
    "data['uncensored'] = 1 - data['censored']\n",
    "\n",
    "# Fit a logistic regression model to predict uncensored status using x2 and x1.\n",
    "ipcw_model = smf.logit(\"uncensored ~ x2 + x1\", data=data).fit(disp=False)\n",
    "\n",
    "# Print logistic regression summary\n",
    "print(\"\\nLogistic Regression Model Summary:\")\n",
    "print(ipcw_model.summary())\n",
    "\n",
    "# Add predicted probability and compute IPCW weight\n",
    "data['p_uncensored'] = ipcw_model.predict(data)\n",
    "\n",
    "# To avoid division by zero, clip the probabilities\n",
    "data['p_uncensored'] = data['p_uncensored'].clip(lower=0.01)\n",
    "\n",
    "# Compute IPCW weight\n",
    "data['ipcw'] = 1.0 / data['p_uncensored']\n",
    "\n",
    "# Display first few rows with weights, formatted for readability\n",
    "print(\"\\nFirst few rows with uncensored status, predicted probabilities, and IPCW weights:\")\n",
    "print(data[['uncensored', 'p_uncensored', 'ipcw']].head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a09a7b",
   "metadata": {},
   "source": [
    "### Step 3: Expanding Data for Sequential Trials\n",
    "In the target trial emulation framework, each patient may be eligible to enter a trial at multiple time points. We create an expanded dataset where each row represents a trial entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e5afd312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expanded Data Shape: (170, 17)\n",
      "\n",
      "First few rows of the expanded data:\n",
      "  id  period  treatment   x1    x2   x3    x4   age  age_s  outcome  censored  eligible  uncensored  p_uncensored  ipcw  trial_period  followup_time\n",
      "1.00    0.00       1.00 1.00  1.15 0.00  0.73 36.00   0.08     0.00      0.00      1.00        1.00          0.91  1.09          0.00           0.00\n",
      "2.00    0.00       0.00 1.00 -0.80 0.00 -0.99 26.00  -0.75     0.00      0.00      1.00        1.00          0.96  1.04          0.00           0.00\n",
      "2.00    1.00       1.00 1.00 -0.98 0.00 -0.99 27.00  -0.67     0.00      0.00      1.00        1.00          0.97  1.03          1.00           0.00\n",
      "3.00    0.00       1.00 0.00  0.57 1.00  0.39 48.00   1.08     0.00      0.00      1.00        1.00          0.87  1.14          0.00           0.00\n",
      "4.00    0.00       0.00 0.00 -0.11 1.00 -1.61 29.00  -0.50     0.00      0.00      1.00        1.00          0.91  1.10          0.00           0.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def expand_trials(df):\n",
    "    \"\"\"\n",
    "    For every row where 'eligible' is 1, create a trial entry.\n",
    "    In a full implementation, this would clone each patient for each eligible period.\n",
    "    Here, we create a simplified version.\n",
    "    \"\"\"\n",
    "    expanded_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        if row['eligible'] == 1:\n",
    "            new_row = row.copy()\n",
    "            new_row['trial_period'] = row['period']\n",
    "            new_row['followup_time'] = 0  # initial follow-up time\n",
    "            # In a complete implementation, you would iterate over subsequent periods\n",
    "            expanded_rows.append(new_row)\n",
    "    return pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Expand the dataset\n",
    "expanded_data = expand_trials(data)\n",
    "\n",
    "# Set pandas display options to ensure the full dataset is visible\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.width', 1000)        \n",
    "pd.set_option('display.max_rows', 10)       \n",
    "\n",
    "# Print the shape of the expanded data\n",
    "print(\"\\nExpanded Data Shape:\", expanded_data.shape)\n",
    "\n",
    "# Display the first few rows of the expanded data in a clean, readable format\n",
    "print(\"\\nFirst few rows of the expanded data:\")\n",
    "print(expanded_data.head().to_string(index=False))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda282b1",
   "metadata": {},
   "source": [
    "### Step 4: Fitting the Marginal Structural Model (MSM)\n",
    "A weighted logistic regression model is used to estimate the causal effect of treatment on the outcome, with covariates including `x2` (a relevant feature), `followup_time` (the duration of follow-up), and `trial_period` (the period during which treatment was administered)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "299c72b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                outcome   No. Observations:                  170\n",
      "Model:                            GLM   Df Residuals:                   180.36\n",
      "Model Family:                Binomial   Df Model:                            4\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -8.7896\n",
      "Date:                Sun, 09 Mar 2025   Deviance:                       17.579\n",
      "Time:                        04:03:24   Pearson chi2:                     56.5\n",
      "No. Iterations:                    25   Pseudo R-squ. (CS):            0.03725\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================================\n",
      "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Intercept                    -25.4713   2.97e+04     -0.001      0.999   -5.81e+04    5.81e+04\n",
      "assigned_treatment            22.1710   2.97e+04      0.001      0.999   -5.81e+04    5.81e+04\n",
      "x2                             0.5568      0.598      0.932      0.352      -0.615       1.728\n",
      "followup_time               2.052e-14   1.88e-11      0.001      0.999   -3.68e-11    3.68e-11\n",
      "np.power(followup_time, 2)          0          0        nan        nan           0           0\n",
      "trial_period                 -21.1004   1.93e+04     -0.001      0.999   -3.78e+04    3.78e+04\n",
      "np.power(trial_period, 2)      1.1655   1186.739      0.001      0.999   -2324.799    2327.130\n",
      "==============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create an 'assigned_treatment' variable\n",
    "expanded_data['assigned_treatment'] = expanded_data['treatment']\n",
    "\n",
    "# Winsorize extreme weights at the 99th percentile\n",
    "q99 = expanded_data['ipcw'].quantile(0.99)\n",
    "expanded_data['ipcw_winsor'] = expanded_data['ipcw'].apply(lambda w: min(w, q99))\n",
    "\n",
    "# Define the outcome model formula\n",
    "formula = (\"outcome ~ assigned_treatment + x2 + followup_time + np.power(followup_time, 2) \"\n",
    "           \"+ trial_period + np.power(trial_period, 2)\")\n",
    "\n",
    "# Fit the weighted logistic regression model\n",
    "msm_model = smf.glm(formula, data=expanded_data,\n",
    "                    family=sm.families.Binomial(),\n",
    "                    freq_weights=expanded_data['ipcw_winsor']).fit()\n",
    "print(msm_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d671c51a",
   "metadata": {},
   "source": [
    "### Step 5: Applying and Integrating Clustering for Enhanced Segmentation\n",
    "In this step, we apply clustering to the baseline dataset to identify distinct subgroups of patients based on specific baseline covariates (e.g., age, and other relevant features). This segmentation allows for more targeted analysis, such as comparing treatment effects or outcomes between different patient clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb20948e",
   "metadata": {},
   "source": [
    "### Step 6: Visualizing Pairwise Relationships of Baseline Covariates by Cluster\n",
    "Lastly, we create pairwise scatter plots to visualize the relationships between the baseline covariates for each cluster. The plot is generated using Seaborn's pairplot function, which allows us to examine the distribution and correlation between multiple variables while grouping them by their respective clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f17543",
   "metadata": {},
   "source": [
    "## **Summary of Findings**\n",
    "\n",
    "### Elbow Method Plot\n",
    "The elbow method was used to determine the optimal number of clusters, which was found to be **three**. This segmentation balances model complexity with explanatory power, highlighting three distinct patient subgroups based on baseline covariates. These subgroups form a foundation for personalized treatment analysis and tailored interventions.\n",
    "\n",
    "### Cluster Summary Visualization\n",
    "The clustering analysis revealed three distinct patient subgroups based on baseline covariates:\n",
    "\n",
    "- **Cluster 0**: Younger patients (mean age ~26.18) with moderate clinical features (x1: 0.33, x2: -0.19, x3: 0.58, x4: 0.50).\n",
    "- **Cluster 1**: Middle-aged patients (mean age ~40.02) with moderate clinical features (x1: 0.45, x2: 0.09, x3: 0.45, x4: -0.26).\n",
    "- **Cluster 2**: Older patients (mean age ~52.19) with distinct clinical profiles (x1: 0.44, x2: 0.00, x3: 0.56, x4: -0.18).\n",
    "\n",
    "These differences emphasize patient heterogeneity, which is critical for developing targeted treatment strategies.\n",
    "\n",
    "### Logistic Regression Model\n",
    "The logistic regression model for predicting uncensored status showed significant coefficients for covariates **x2** and **x1**, indicating their importance in predicting patient outcomes. This model is essential for adjusting for informative censoring and ensuring unbiased treatment effect estimates.\n",
    "\n",
    "### Expanded Data\n",
    "The dataset was expanded to **170 rows**, each representing a trial entry. This expansion enables a comprehensive analysis of treatment effects over time, capturing dynamic treatment eligibility and outcomes. The expanded dataset includes variables such as `trial_period` and `followup_time`, which are crucial for sequential trial analysis.\n",
    "\n",
    "### Marginal Structural Model (MSM)\n",
    "The MSM, fitted using weighted logistic regression, indicated that both treatment and baseline clinical features (e.g., **x2**) significantly impact patient outcomes. This model underscores the importance of considering these factors in causal inference models to derive meaningful insights into treatment effects.\n",
    "\n",
    "### Cluster Characteristics\n",
    "The clusters revealed distinct patient subgroups with varying characteristics, supporting the development of personalized interventions tailored to specific patient profiles. Pairwise comparisons between clusters further highlighted differences in clinical features and treatment outcomes, reinforcing the need for subgroup-specific analyses.\n",
    "\n",
    "### Pairwise Comparisons\n",
    "- **Cluster 0 vs. Cluster 1**: Cluster 0 patients are younger with slightly lower **x2** values, while Cluster 1 patients are middle-aged with higher **x1** values. This suggests that younger patients may respond differently to treatments compared to middle-aged patients.\n",
    "- **Cluster 1 vs. Cluster 2**: Cluster 2 patients are older with higher **x3** values, indicating that older patients may have different treatment needs and outcomes compared to middle-aged patients.\n",
    "- **Cluster 0 vs. Cluster 2**: Cluster 0 patients are significantly younger with different clinical profiles, suggesting that age and clinical features play a crucial role in treatment response.\n",
    "\n",
    "## **Key Analytical Insights**\n",
    "\n",
    "- **Treatment Effects**: The **Marginal Structural Model (MSM)** results revealed that **assigned_treatment** and **x2** significantly impact patient outcomes. The coefficient for **assigned_treatment** was **22.1710**, and for **x2**, it was **0.5568**, indicating their importance in determining patient outcomes. This underscores the critical role of treatment and baseline clinical features in influencing patient health trajectories.\n",
    "\n",
    "- **Cluster Characteristics**: Clustering identified **three distinct patient subgroups** based on baseline covariates:\n",
    "  - **Cluster 0**: Younger patients (mean age ~26.18) with moderate clinical features (x1: 0.33, x2: -0.19, x3: 0.58, x4: 0.50).\n",
    "  - **Cluster 1**: Middle-aged patients (mean age ~40.02) with moderate clinical features (x1: 0.45, x2: 0.09, x3: 0.45, x4: -0.26).\n",
    "  - **Cluster 2**: Older patients (mean age ~52.19) with distinct clinical profiles (x1: 0.44, x2: 0.00, x3: 0.56, x4: -0.18).  \n",
    "  These subgroups suggest potential for **personalized treatment strategies** tailored to the unique characteristics of each subgroup.\n",
    "\n",
    "- **Censoring Adjustment**: The **Inverse Probability of Censoring Weights (IPCW)** method effectively adjusted for censoring, ensuring unbiased and reliable treatment effect estimates. The logistic regression model for predicting uncensored status showed significant coefficients for **x2** and **x1**, with **x2** having a coefficient of **-0.4706** and **x1** having a coefficient of **0.7019**, highlighting their importance in the censoring mechanism.\n",
    "\n",
    "## **Limitations and Considerations**\n",
    "   - The MSM and clustering techniques introduced additional complexity to the analysis. Ensuring the robustness and interpretability of these models is crucial.\n",
    "   - The accuracy of the findings depends on the quality and completeness of the dataset. Missing data or measurement errors could impact the results.\n",
    "   - The findings are based on a specific dataset. Further validation with other datasets is necessary to assess the generalizability of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a564e4",
   "metadata": {},
   "source": [
    "\n",
    "## **Conclusion, Key Findings, and Future Directions**\n",
    "\n",
    "### **Conclusion**\n",
    "The integration of clustering techniques into Target Trial Emulation (TTE) significantly enhances the ability to identify distinct subgroups within a population, leading to more precise and personalized treatment effect estimates. This study demonstrated how Marginal Structural Models (MSM) and Inverse Probability of Censoring Weights (IPCW) can improve the robustness of causal inference when analyzing observational data. The results suggest that clustering can provide valuable insights into treatment heterogeneity, allowing researchers to tailor interventions based on patient characteristics.\n",
    "\n",
    "### **Key Findings**\n",
    "- **Clustering Identified Distinct Subgroups**: The application of clustering techniques led to the identification of three distinct patient groups:\n",
    "  - **Cluster 0**: Younger patients (~26 years old) with moderate clinical features.\n",
    "  - **Cluster 1**: Middle-aged patients (~40 years old) with moderate clinical features.\n",
    "  - **Cluster 2**: Older patients (~52 years old) with distinct clinical profiles.\n",
    "  - These findings highlight the potential for **personalized treatment strategies** based on patient characteristics.\n",
    "\n",
    "- **Censoring Adjustment Was Effective**:\n",
    "  - The **IPCW method** successfully adjusted for censoring, ensuring unbiased treatment effect estimates.\n",
    "  - Logistic regression results showed that **x1 and x2** were significant predictors of censoring, influencing the final estimates.\n",
    "\n",
    "- **Treatment Effect Estimation Was Improved**:\n",
    "  - The integration of MSM allowed for a more comprehensive assessment of treatment effects.\n",
    "  - The methodology demonstrated the importance of considering both confounding and censoring adjustments in observational studies.\n",
    "\n",
    "### **Implications & Future Directions**\n",
    "- **Enhancing Model Interpretability**: While the combination of MSM and clustering techniques improved analytical depth, it also introduced additional complexity. Future work should focus on refining these models to ensure interpretability and usability in clinical decision-making.\n",
    "- **Data Quality Considerations**: The reliability of the findings is dependent on the completeness and accuracy of the dataset. Addressing missing values and minimizing measurement errors should be a priority in future research.\n",
    "- **Generalizability Testing**: This study was conducted using a specific dataset. To validate the robustness of the findings, future research should apply these techniques to other datasets across different populations and medical conditions.\n",
    "- **Expanding to Other Clinical Applications**: The methodological framework introduced in this study can be extended to various disease areas and treatment scenarios. Exploring the effectiveness of clustering-enhanced TTE in different clinical contexts could further establish its value in medical research.\n",
    "- **Integration with Machine Learning**: Future studies may explore the integration of deep learning and advanced machine learning techniques to refine clustering methodologies and improve the accuracy of treatment effect estimates.\n",
    "\n",
    "By addressing these considerations, future research can build on the insights gained from this study to enhance the practical applicability of Target Trial Emulation in healthcare and epidemiological studies.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
